{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.autonotebook import tqdm\n",
    "from collections import defaultdict\n",
    "import json\n",
    "\n",
    "from words import words, answers\n",
    "from utilities import combinations\n",
    "\n",
    "outcomes = combinations('gyb', 5)\n",
    "\n",
    "words = set(words + answers)\n",
    "answers = set(answers)\n",
    "\n",
    "A = np.array([[l for l in w] for w in answers])\n",
    "W = np.array([[l for l in w] for w in words])\n",
    "alphabet = 'qwertyuiopasdfghjklzxcvbnm'\n",
    "letter_at_index = {(i, l) : {''.join(w) for w in A[A[:, i] == l]} for l in alphabet for i in range(5)}\n",
    "letter_not_at_index = {(i, l) : {''.join(w) for w in A[(A[:, i] != l)]} for l in alphabet for i in range(5)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`allowed_by` takes in a guess, outcome, list of possible words, and utility dictionaries $\\rightarrow$ returns set of words allowed by guess/outcome combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allowed_by(guess, outcome, words, at_index = letter_at_index, not_at_index = letter_not_at_index):\n",
    "    \n",
    "    words = words.copy()\n",
    "    O = np.array([l for l in outcome])\n",
    "    G = np.array([l for l in guess])\n",
    "    I = np.arange(5)\n",
    "    \n",
    "    non_green_idxs = {l: {*I[~((O == 'g') & (G == l))]} for l in G}\n",
    "        \n",
    "    for idx in range(5):\n",
    "        l = guess[idx]\n",
    "        o = outcome[idx]\n",
    "        \n",
    "        # filter for greens first\n",
    "        if o == 'g':\n",
    "            words = words.intersection(at_index[(idx, l)])\n",
    "            \n",
    "            if len(words) == 0:\n",
    "                return words\n",
    "            \n",
    "        # then yellows\n",
    "        elif o == 'y':\n",
    "            \n",
    "            # retain all words without the yellow letter at its spot\n",
    "            words = words.intersection(not_at_index[(idx, l)])\n",
    "            \n",
    "            # retain all words with the yellow letter but not in the green spots\n",
    "            in_word = set()\n",
    "            for j in (non_green_idxs[l] - {idx}):\n",
    "                in_word = in_word.union(at_index[(j, l)])\n",
    "                \n",
    "            words = words.intersection(in_word)\n",
    "            \n",
    "            if len(words) == 0:\n",
    "                return words\n",
    "            \n",
    "        # then blacks\n",
    "        elif o == 'b':\n",
    "                        \n",
    "            # retain all words without the letter in any non-green spot\n",
    "            for j in non_green_idxs[l]:\n",
    "                words = words.intersection(not_at_index[(j, l)])\n",
    "                \n",
    "                if len(words) == 0:\n",
    "                    return words\n",
    "            \n",
    "        else:\n",
    "            raise Exception(f'outcome can only include g, y, b, but is {outcome}')\n",
    "            \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For every guess/outcome combination, save the resultant set of possible answers if its measure is > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_first_level(file):\n",
    "\n",
    "    first_level = {(g, outcome) : allowed_by(g, outcome, answers) for g in tqdm(words) for outcome in outcomes}\n",
    "\n",
    "    with open(file, 'w') as file:\n",
    "        json.dump({'/'.join(k): [*v] for k, v in first_level.items() if len(v) > 0}, file)\n",
    "        \n",
    "    entropies = {}\n",
    "\n",
    "    for k, v in first_level.items():\n",
    "\n",
    "        word = k[:5]\n",
    "\n",
    "        if word not in entropies:\n",
    "            entropies[word] = 0\n",
    "\n",
    "        n = len(v)\n",
    "\n",
    "        p = n / len(answers)\n",
    "\n",
    "        entropies[word] -= p * np.log2(p)\n",
    "\n",
    "    with open('first_level_entropies.json', 'w') as file:\n",
    "        json.dump(entropies, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the results of the previous computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_level.json', 'r') as file:\n",
    "    first_level = {k : set(v) for k, v in json.load(file)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('first_level_entropies.json', 'r') as file:\n",
    "    entropies = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select the ten highest entropy words as finalists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalists = sorted(entropies, key = entropies.get)[::-1][:10]\n",
    "keys = [k for k in first_level if any(f in k for f in finalists)]\n",
    "keys = sorted(keys, key = lambda x: len(first_level[x]))\n",
    "\n",
    "print('Finalists:'+'\\n\\t'.join(finalists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edf4823b3cc8414db74a3dc787c19b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1377.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "second_level = {}\n",
    "\n",
    "for k1 in tqdm(keys):\n",
    "    g1 = np.array(list(k1.split('/')[0]))\n",
    "    o1 = np.array(list(k1.split('/')[1]))\n",
    "    \n",
    "    remaining = first_level[k1]\n",
    "    \n",
    "    if ''.join(o1) == 'ggggg':\n",
    "        second_level.update({k1:None})\n",
    "    \n",
    "    if len(remaining) <= 2:\n",
    "        for r in remaining:\n",
    "            second_level.update({k1 + f'//{r}/ggggg':None})\n",
    "        continue\n",
    "    \n",
    "    for outcome in outcomes:\n",
    "        \n",
    "        # Make a list of guesses consistent with this outcome given prior information\n",
    "        G = A.copy()\n",
    "        o2 = np.array(list(outcome))\n",
    "        \n",
    "        # Where both outcomes are green, guesses must have same letter\n",
    "        both_green = (o1 == 'g') & (o2 == 'g')\n",
    "        if sum(both_green) > 0:\n",
    "            G = G[(G[:, both_green] == g1[both_green]).min(1)]\n",
    "            \n",
    "        # Where both guesses are the same, outcomes must be the same\n",
    "        G = G[((G != g1) | (o2 == o1)).min(1)]\n",
    "        \n",
    "        # Note: there are more conditions one could add but not clear how much of a speed-up they obtain?\n",
    "        \n",
    "        for g2 in G:\n",
    "            guess = ''.join(g2)\n",
    "            k2 = f'{guess}/{outcome}'\n",
    "            \n",
    "            if k2 in first_level:\n",
    "                key = k1 + '//' + k2\n",
    "                result = first_level[k2].intersection(remaining)\n",
    "                if len(result) > 0:\n",
    "                    second_level[key] = [*result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('second_level.json', 'w') as file:\n",
    "    json.dump(second_level, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: find best first word using two-level search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_guess_2d = {}\n",
    "\n",
    "for k, v in second_level.items():\n",
    "    \n",
    "    first, second = k.split('//')\n",
    "    \n",
    "    n = len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies2 = {}\n",
    "\n",
    "for k, v in tqdm(second_level.items()):\n",
    "    \n",
    "    word = k.split('/')[0]\n",
    "    \n",
    "    if word not in entropies2:\n",
    "        entropies2[word] = 0\n",
    "    \n",
    "    if v is not None:\n",
    "        n = len(v)\n",
    "    \n",
    "        p = n / len(answers)\n",
    "    \n",
    "        entropies2[word] -= p * np.log2(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies2 = entropies.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>trace</th>\n",
       "      <td>5.830549</td>\n",
       "      <td>17631.485169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irate</th>\n",
       "      <td>5.831397</td>\n",
       "      <td>17674.686747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>salet</th>\n",
       "      <td>5.834582</td>\n",
       "      <td>17717.598171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crate</th>\n",
       "      <td>5.834874</td>\n",
       "      <td>17662.149248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slate</th>\n",
       "      <td>5.855775</td>\n",
       "      <td>17730.111401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reast</th>\n",
       "      <td>5.865457</td>\n",
       "      <td>17718.300239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raile</th>\n",
       "      <td>5.865710</td>\n",
       "      <td>17830.984431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raise</th>\n",
       "      <td>5.877910</td>\n",
       "      <td>17782.917604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roate</th>\n",
       "      <td>5.882779</td>\n",
       "      <td>17839.056084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>soare</th>\n",
       "      <td>5.885960</td>\n",
       "      <td>17868.109780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1\n",
       "trace  5.830549  17631.485169\n",
       "irate  5.831397  17674.686747\n",
       "salet  5.834582  17717.598171\n",
       "crate  5.834874  17662.149248\n",
       "slate  5.855775  17730.111401\n",
       "reast  5.865457  17718.300239\n",
       "raile  5.865710  17830.984431\n",
       "raise  5.877910  17782.917604\n",
       "roate  5.882779  17839.056084\n",
       "soare  5.885960  17868.109780"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([entropies, entropies2]).T.reindex(entropies2).sort_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
